{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "bJyo0RjZdMa0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import utils, transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from skimage import io, transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZYPdJP7gLnJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_landmarks(image, landmarks):\n",
        "    \"\"\"Show image with landmarks\"\"\"\n",
        "    plt.imshow(image)\n",
        "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=40, marker='.', c='r')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxSWmFalk-rO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CrÃ©ation du dataset"
      ]
    },
    {
      "metadata": {
        "id": "esQbH596pN7v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Extract"
      ]
    },
    {
      "metadata": {
        "id": "hDV7tJ7opQSO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://download.pytorch.org/tutorial/faces.zip\n",
        "!unzip faces.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8V--w7V3hzgc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FaceLandmarksDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.landmarks_frame = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.landmarks_frame)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0])\n",
        "        image = io.imread(image_name)\n",
        "        landmarks = self.landmarks_frame.iloc[idx, 1:].as_matrix()\n",
        "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
        "        sample = { 'image': image, 'landmarks': landmarks}\n",
        "        \n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "            \n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "How-UlSpiaAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "root_dir = \"faces\"\n",
        "csv_file = os.path.join(root_dir, \"face_landmarks.csv\")\n",
        "face_dataset = FaceLandmarksDataset(csv_file=csv_file, root_dir=root_dir)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ZjYcFgbpTzl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transform"
      ]
    },
    {
      "metadata": {
        "id": "yhtoTFEeniHA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Rescale(object):\n",
        "    \n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "        \n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "        h, w = image.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "            \n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "        image = transform.resize(image, (new_h, new_w))\n",
        "        landmarks = landmarks * [new_w / w, new_h / h]\n",
        "        \n",
        "        return {'image': image, 'landmarks': landmarks}\n",
        "    \n",
        "    \n",
        "class RandomCrop(object):\n",
        "    \"\"\"Crop randomly the image in a sample.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If int, square crop\n",
        "            is made.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        if isinstance(output_size, int):\n",
        "            self.output_size = (output_size, output_size)\n",
        "        else:\n",
        "            assert len(output_size) == 2\n",
        "            self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        new_h, new_w = self.output_size\n",
        "\n",
        "        top = np.random.randint(0, h - new_h)\n",
        "        left = np.random.randint(0, w - new_w)\n",
        "\n",
        "        image = image[top: top + new_h,\n",
        "                      left: left + new_w]\n",
        "\n",
        "        landmarks = landmarks - [left, top]\n",
        "\n",
        "        return {'image': image, 'landmarks': landmarks}\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C X H X W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return {'image': torch.from_numpy(image),\n",
        "                'landmarks': torch.from_numpy(landmarks)}\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MM6VxZ_wpnYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transformed_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv',\n",
        "                                           root_dir='faces/',\n",
        "                                           transform=transforms.Compose([\n",
        "                                               Rescale(256),\n",
        "                                               RandomCrop(224),\n",
        "                                               ToTensor()\n",
        "                                           ]))\n",
        "\n",
        "for i in range(len(transformed_dataset)):\n",
        "    sample = transformed_dataset[i]\n",
        "\n",
        "    print(i, sample['image'].size(), sample['landmarks'].size())\n",
        "\n",
        "    if i == 3:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnb90r2fXoii",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load"
      ]
    },
    {
      "metadata": {
        "id": "FOTJvZ2RI-lU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
        "                        shuffle=True, num_workers=4)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}